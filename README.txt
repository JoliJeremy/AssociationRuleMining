Lab 6 - Association Rule Mining based Classification
Manjari Akella
Jeremy LeDonne
12/5/14

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~OVERVIEW~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
All the files for Lab 6 can be found at the directory:
/home/3/ledonne/cse5243/lab6/

In the directory are the following files:
1. Lab6.docx                           Lab 6 report write up
2. README.txt                          This file you are reading
3. ruleMining.py	               Python script for rule mining and classification		
4. KMeansClustering.jar                JAR file to cluster data
5. apriori.exe 			       .exe which implements the apriori alogrithm (Windows OS)
6. FV3.txt 			       The transactional feature vector file
7. FV4.txt                             The data vector style feature vector file
8. results.txt 			       Results file with information about accuracy, efficieny etc.
9. Lab6.sh                             Shell script to run the python scripts

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~IMPLEMENTATION~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ruleMining.py
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The ruleMining.py script implements the Association Rule mining for both the case of non clustering and clustering.
This uses 3-fold cross validation and first starts off by splitting the data into 3 partitions.  Two of the partitions
are combined to form the training set and the remaining partition is used as the test set.  The script keeps track of
the total time to run, the time to cluster, and the time to create the Association rules. 

The case of non clustering is relatively simple.  The training set is converted into a comma delimited file where
each line represents one feature vector.  The line contains a list of both the words for the reuters document as
well as the words that are considered class labels - topics and places.  This comma delimited file is then used
to run the apriori software in the python code (function is callApriori()).

The rules of the apriori software are written to a text file.  The funcion generateClassifiers() is used to take
in a list of the names of the rule files generated by the apriori software and create classifiers based on the 
rules.  This function opens and reads the rules, prunes out bad rules (based on the criteria specified in the Report),
and then rank orders the rules in descending order by confidence (using the highest support in the case of ties).  That
is, the highest ranking rule has the highest confidence.  Last, a default class label is added at the end of the rules.
This is used in the case where none of the rules apply to a given transaction.  The default class label is chosen as
the most frequently occurring class in the rules.  A document in the test set is then classified by using the class
of the highest confidence rule that applies to the test vector.

For the case of clustering, the java KMeansClustering.java file from the clustering lab was used to perform clustering
with Manhattan Distance. The script first calls generateClusteringSet() in order to list out the data that needs
to be clustered.  The training set is not sufficient because it is composed of feature vectors from FV3.txt, which
is merely a transactional feature vector. generateClusteringSet() uses the these feature vectors to find its 
corresponding match in FV4.txt, which holds that data matrix values.  These values count he occurrences of words.
The feature vector extracted is converted to binary and stored into a list to be included for clustering.
The function callKMeans() is then invoked to cluster the documents and returns the list of centroids.  Once this 
is done, the generateRulePartitions() takes in these centroids and for each vector in the training set, places it
in the cluster of its closest centroid.  Again FV4.txt has to be used to get the data matrix representation feature
vector to do a distance calculation of which centroid is closest.  

Once all the training set is grouped into its corresponding closest cluster, the apriori software is used to generate
the rules for each cluster.  The set of clusters is looped over and the callApriori function is used.  Once
the rules are created and printed to a file, the files are looped over and the classifiers for each cluster are made
by calling generateClassifiers().  The pruning and ranking of rules is done identical to the description above.  Finally,
the testing set is looped over to classify.  In order to do this, each element of the testing set needs to be grouped
with one of the clusters created.  The findClosestCentroid() method is used to determine which centroid the test vector
is closest to.  Once the closest centroid is found, the test vector is classified by using the association rules for
its corresponding cluster.  In both the non clustering and clustering cases, the class label is assigned using
the classify() functio and the isCorrectClassification method checks to see if its assigned class label matches one of
its actually topics or places in the data vector.  

The last implementation detail that needs to be mentioned is the use of clustering.  when a large amount of data is used
to generate the Association rules, the creation of rules is relatively fast because many item sets do not meet the 
support supplied.  However, when the size of a cluster becomes smaller, especially under the size of 100, a majority
of the itemsets generated are over the given support value.  Therefore, many more itemsets are considered and a significant
amount of memory is consumed.  On several of our clusters under size 100, the itemset generation consumed all of memory and
took up to 12 GB of RAM.  In order to deal with this, the commands were slightly modified to the apriori software.  In the
case where the size of the cluster was larger or equal to 100, nothing was changed and the user's specified support and
confidence were kept the same.  In the case where the size of the cluster was between 2 and 9, a default class label of
"defaultClassLabel10" was assigned.  When the cluster size was between 10 and 19, the support and confidence to the 
apriori software were changed to be 90 and 70, respectively.  Finally, when the size of the cluster was between 20 and 99,
the support and confidence to the apriori software were changed to be 70 and 70, respectively.  This allowed for rules to
still be generated without consuming all of memory.  

KMeanClustering.jar
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
This JAR file implements the k-means clustering algorithm. Code was borrowed from Lab4. It reads in an arff file and clusters
it using a specified distance metric. It takes 3 input arguments - arff file name, number of clusters and the distance metric 
to be used. The JAR file was generated from a java file which uses weka libraries to cluster the data. This file is called 
from within the python script wherever appropriate. The following is the syntax to call this file :

java -jar KMeansClustering.jar arffFile numberOfClusters distanceMetric

So the following example call will run k-means on reuters.arff file, with k being 8 and the distance metric as Manhattan:

java -jar KMeansClustering.jar reuters.arff 8 1

This JAR returns a text file, centroids.txt which contains the centroids of the clusters generated.

apriori.exe: Implementation by Christian Borgelt, European Center for Soft Computing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
This script implements the the apriori algorithm to generate frequent item sets and association rules among other things. It 
takes in an input file which has transactional data and writes the results out to either the console or an output file. This 
executable is called from with the python script wherever appropriate.  The implementation allows several command line options 
to allow for flexibility in usage. The following are the command line options used by us:

-k - represents the record seperator for the items in the output file(Used: ,)
-m - minimum number of items per rule (Used: 2)
-t - target to generate(rules(r)/frequent item set(s)/etc., Used: r)
-o - uses original definition of support (antecedent and consequent)
-s - minimum support value
-c - minimum confidence value
infile - file with transactions 
outfile - file to which rules are written

The rules are written out in the following form:

consequent<-antecedent (support, confidence)

The following example command will find rules in the file infile.txt and write them to outfile.txt. It will use a minimium 
support of 20 and confidence of 60. It will use the original definition of support and the minimum number of items in a rule 
will be 2.

apriori -k, -m2 -tr -o -s20 -c60 infile.txt outfile.txt

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~RUNNING THE PROGRAMS~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Lab6.sh
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
This script runs the python script ruleMining.py for a bunch of different parameter settings.

ruleMining.py
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
This script has 5 command line options. These are as follows:

-s, --support                   support value to be used by the apriori algorithm (Default: 20)
-c, --confidence                confidence value to be used by the apriori algorithm (Default: 60)
-k, --numOfClusters             number of clusters in case clutering is used (1 represents no clustering, Default: 1)
-d, --distance                  distance metric to use for clustering (1: Manhattan, 2:Euclidean, Default: 1) 
-a, --sampling                  sample size in case of sampling (Default: 20,000 to represent entire set)	

The following is an example command to call the program - 

python ruleMining.py -k 1 -d 1 -s 20 -c 80

This command will run on the entire data set, without clustering. The apriori algorithm will use minimum support as 20 and confidence as 80

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ADDITIONAL SOFTWARE~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~		
If the script ruleMining.py is run offline, make sure there is enough memory on whichever system is being used. Also needed are JRE and the apriori software which can be found at the following links:

JRE: http://www.oracle.com/technetwork/java/javase/downloads/jre7-downloads-1880261.html
Apriori: http://www.borgelt.net/apriori.html

Choose the appropriate version based on the OS.


***Note: 1. All support and confidence values listed here indicate a percentage value.
		 2. If you would like to see an in-person demo of how to run any part of this lab, please contact:
         ledonne.5@osu.edu or akella.4@osu.edu
		 
